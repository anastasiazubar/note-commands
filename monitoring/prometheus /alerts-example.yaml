# additionalPrometheusRulesMap -> PrometheusValues.yaml
# in this example 2 rule groups: MainGroupAlerts and ApplicationName-SeparateAlertGroup
# severity used for filters alerts based on groups as well as slack templates are different for critical/warning alerts.
# group used for filters alerts based on groups for sending alerts to different channel


additionalPrometheusRulesMap: 
  rule-name:
    groups:
    - name: MainGroupAlerts
      rules:
      - alert: ClusterName-ENV-Kubernetes-Pod-Not-Healthy
        annotations:
          description: Kubernetes Pod {{ $labels.pod }} under namespace {{ $labels.namespace }} not healthy {{ $labels.instance }}
          summary: Pod has been in a non-ready state for longer than 5 minutes.
        expr: min_over_time(sum by (namespace, pod) (kube_pod_status_phase{namespace!="namespace_name_you_don't_want_to_check"",phase=~"Pending|Unknown|Failed"})[2m:1m]) > 0
        for: 5m
        labels:
          severity: critical
          group: MainGroupAlerts 
      - alert: ClusterName-ENV-Kubernetes-Pod-CrashLooping
        annotations:
          description: Pod {{ $labels.pod }} is crash looping
          summary: Kubernetes pod {{ $labels.pod }}  in crash looping status
        expr: increase(kube_pod_container_status_restarts_total{namespace!="namespace_name_you_don't_want_to_check""}[1m]) > 3
        for: 5m
        labels:
          severity: critical
          group: MainGroupAlerts 
      - alert: ClusterName-ENV-Kubernetes-Node-Not-Ready
        annotations:
          description: Node {{ $labels.node }} has been unready for a long time
          summary: Kubernetes Node ready (instance {{ $labels.instance }})
        expr: kube_node_status_condition{condition="Ready",status="true"} == 0
        for: 10m
        labels:
          severity: warning
          group: MainGroupAlerts 
      - alert: ClusterName-ENV-Kubernetes-Memory-Pressure
        annotations:
          description: |-
            Node {{ $labels.node }} has MemoryPressure condition
          summary: Kubernetes memory pressure on node {{ $labels.node }}
        expr: kube_node_status_condition{condition="MemoryPressure",status="true"} == 1
        for: 5m
        labels:
          severity: warning
          group: MainGroupAlerts 
      - alert: ClusterName-ENV-Kubernetes-Disk-Pressure
        annotations:
          description: |-
            Node {{ $labels.node }} has DiskPressure condition
          summary: Kubernetes disk pressure (instance {{ $labels.instance }})
        expr: kube_node_status_condition{condition="DiskPressure",status="true"} == 1
        for: 5m
        labels:
          severity: warning
          group: MainGroupAlerts 
      - alert: ClusterName-ENV-Kubernetes-Network-Unavailable
        annotations:
          description: |-
            {{ $labels.node }} has NetworkUnavailable condition
          summary: Kubernetes network unavailable (instance {{ $labels.instance }})
        expr: kube_node_status_condition{condition="NetworkUnavailable",status="true"} == 1
        for: 5m
        labels:
          severity: warning
          group: MainGroupAlerts 
      - alert: ClusterName-ENV-Kubernetes-Out-Of-Capacity
        annotations:
          description: |-
            {{ $labels.node }} is out of capacity
          summary: Kubernetes out of capacity (instance {{ $labels.instance }})
        expr: sum by (node) ((kube_pod_status_phase{phase="Running"} == 1) + on(uid)
          group_left(node) (0 * kube_pod_info{pod_template_hash=""})) / sum by (node)
          (kube_node_status_allocatable{resource="pods"}) * 100 > 90
        for: 5m
        labels:
          severity: warning
          group: MainGroupAlerts 
      - alert: ClusterName-ENV-Kubernetes-Container-Oom-Killer
        annotations:
          description: |-
            Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} has been OOMKilled {{ $value }} times in the last 10 minutes.
          summary: Kubernetes container oom killer (instance {{ $labels.instance }})
        expr: (kube_pod_container_status_restarts_total{namespace!="namespace_name_you_don't_want_to_check""} - kube_pod_container_status_restarts_total{namespace!="namespace_name_you_don't_want_to_check""}
          offset 10m >= 1) and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{namespace!="namespace_name_you_don't_want_to_check"",reason="OOMKilled"}[10m])
          == 1
        for: 5m
        labels:
          severity: critical
          group: MainGroupAlerts 
      - alert: ClusterName-ENV-Kubernetes-PersistentvolumeclaimPending
        annotations:
          description: |-
            PersistentVolumeClaim {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is pending
          summary: Kubernetes PersistentVolumeClaim pending (instance {{ $labels.instance}})
        expr: kube_persistentvolumeclaim_status_phase{namespace!="namespace_name_you_don't_want_to_check"",phase="Pending"} == 1
        for: 5m
        labels:
          severity: critical
          group: MainGroupAlerts 
      - alert: ClusterName-ENV-Kubernets-VolumeOutOfDiskSpace
        annotations:
          description: |-
            Volume is almost full (< 10% left)
          summary: Kubernetes Volume out of disk space (instance {{ $labels.instance}})
        expr: kubelet_volume_stats_available_bytes{namespace!="namespace_name_you_don't_want_to_check""} / kubelet_volume_stats_capacity_bytes{namespace!="namespace_name_you_don't_want_to_check""} * 100 < 10
        for: 5m
        labels:
          severity: critical
          group: MainGroupAlerts 
      - alert: ClusterName-ENV-Kubernetes-Deployment-Replicas-Mismatch
        annotations:
          description: Deployment Replicas mismatch
          summary: Kubernetes Deployment replicas mismatch
        expr: kube_deployment_spec_replicas{namespace!="namespace_name_you_don't_want_to_check""} != kube_deployment_status_replicas_available{namespace!="namespace_name_you_don't_want_to_check""}
        for: 5m
        labels:
          severity: critical
          group: MainGroupAlerts 
      - alert: ClusterName-ENV-HostOutOfMemory
        annotations:
          description: |-
            Node memory is filling up (< 10% left)
          summary: Host out of memory (instance {{ $labels.instance }})
        expr: node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes * 100 < 10
        for: 5m
        labels:
          severity: warning
          group: MainGroupAlerts 
      - alert: ClusterName-ENV-TargetMissing
        annotations:
          description: “A Prometheus Target has gone missing, please investigate”
          summary: “Prometheus Target Missing (instance {{ $labels.instance }})”
        expr: up == 0
        for: 10m
        labels:
          severity: critical
          group: MainGroupAlerts 
      - alert: ClusterName-ENV-Application-Endpoint-Status
        annotations:
          description: “Application endpoint is down. Please investigate”
          summary: “Application endpoint (instance {{ $labels.instance }}) is down. Please investigate)”
        expr: probe_success{instance!~"https://endpoint-no-need-to-check-wildcard"} ==  0
        for: 5m
        labels:
          severity: critical
          group: MainGroupAlerts 
    - name: ApplicationName-SeparateAlertGroup
      rules:
      - alert: ApplicationName-ENV-Kubernetes-Pod-Not-Healthy
        annotations:
          description: Kubernetes Pod {{ $labels.pod }} under namespace {{ $labels.namespace }} not healthy {{ $labels.instance }}
          summary: Pod has been in a non-ready state for longer than 5 minutes.
        expr: min_over_time(sum by (namespace, pod) (kube_pod_status_phase{namespace=~"namespace-name-you-need-to-check".*",phase=~"Pending|Unknown|Failed"})[2m:1m]) > 0
        for: 5m
        labels:
          severity: critical 
          app: ApplicationName
      - alert: ApplicationName-ENV-Kubernetes-Deployment-Replicas-Mismatch
        annotations:
          description: Deployment Replicas mismatch
          summary: Kubernetes Deployment replicas mismatch
        expr: kube_deployment_spec_replicas{namespace=~"namespace-name-you-need-to-check".*"} != kube_deployment_status_replicas_available{namespace=~"namespace-name-you-need-to-check".*"}
        for: 5m
        labels:
          severity: critical
          app: ApplicationName
      - alert: ApplicationName-ENV-Kubernetes-Pod-CrashLooping
        annotations:
          description: Pod {{ $labels.pod }} is crash looping
          summary: Kubernetes pod {{ $labels.pod }}  in crash looping status
        expr: increase(kube_pod_container_status_restarts_total{namespace=~"namespace-name-you-need-to-check".*"}[1m]) > 3
        for: 5m
        labels:
          severity: critical
          app: ApplicationName
      - alert: ApplicationName-ENV-Kubernetes-Container-Oom-Killer 
        annotations:
          description: Container {{ $labels.container }} in pod {{ $labels.namespace }}/{{ $labels.pod }} has been OOMKilled {{ $value }} times in the last 10 minutes.
          summary: Kubernetes container oom killer (instance {{ $labels.instance }})
        expr: (kube_pod_container_status_restarts_total{namespace=~"namespace-name-you-need-to-check".*"} - kube_pod_container_status_restarts_total{namespace=~"namespace-name-you-need-to-check".*"}
          offset 10m >= 1) and ignoring (reason) min_over_time(kube_pod_container_status_last_terminated_reason{namespace=~"namespace-name-you-need-to-check".*",reason="OOMKilled"}[10m]) 
          == 1
        for: 5m
        labels:
          severity: critical
          app: ApplicationName
      - alert: ApplicationName-ENV-Kubernetes-PersistentvolumeclaimPending
        annotations:
          description: |-
            PersistentVolumeClaim {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is pending
          summary: Kubernetes PersistentVolumeClaim pending (instance {{ $labels.instance}})
        expr: kube_persistentvolumeclaim_status_phase{namespace=~"namespace-name-you-need-to-check".*",phase="Pending"} == 1
        for: 5m
        labels:
          severity: critical
          app: ApplicationName
      - alert: ApplicationName-ENV-Kubernets-VolumeOutOfDiskSpace
        annotations:
          description: |-
            Volume is almost full (< 10% left)
          summary: Kubernetes Volume out of disk space (instance {{ $labels.instance}})
        expr: kubelet_volume_stats_available_bytes{namespace=~"namespace-name-you-need-to-check".*"} / kubelet_volume_stats_capacity_bytes{namespace=~"namespace-name-you-need-to-check".*"} * 100 < 10
        for: 5m
        labels:
          severity: critical
          app: ApplicationName
      - alert: ApplicationName-ENV-Application-Endpoint-Status
        annotations:
          description: “Application endpoint is down. Please investigate”
          summary: “Application endpoint (instance {{ $labels.instance }}) is down. Please investigate)”
        expr: probe_success{instance=~"https://endpoint-need-to-check-wildcard"} == 0
        for: 5m
        labels:
          severity: critical
          group: ApplicationName
          
